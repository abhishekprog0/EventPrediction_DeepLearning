{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import quandl\n",
    "import numpy as np\n",
    "import quandl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import talib\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rc('figure', figsize=(20, 8), dpi=100)\n",
    "from datetime import datetime\n",
    "path = os.getcwd()\n",
    "path = path + \"/Desktop/ProjectData/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Technical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingAverages:\n",
    "    \n",
    "    def _init_(self):\n",
    "        pass\n",
    "    def SMA(self, data, factor, days):\n",
    "    \n",
    "        data[\"SMA_\"+ str(days) + \"_\" + factor] = talib.SMA(data[factor], timeperiod=days)\n",
    "        return data\n",
    "    \n",
    "    def EMA(self, data, factor, days):\n",
    "    \n",
    "        data[\"EMA_\"+ str(days) + \"_\" + factor] = talib.EMA(data[factor], timeperiod=days)\n",
    "        return data\n",
    "    \n",
    "    def DEMA(self, data, factor, days):\n",
    "    \n",
    "        data[\"DEMA_\"+ str(days) + \"_\" + factor] = talib.DEMA(data[factor], timeperiod=days)\n",
    "        return data\n",
    "    \n",
    "    def HT(self, data, factor):\n",
    "    \n",
    "        data[\"HT_\" + factor] = talib.HT_TRENDLINE(data[factor])\n",
    "        return data\n",
    "    \n",
    "    def KAMA(self, data, factor, days):\n",
    "    \n",
    "        data[\"KAMA_\"+ str(days) + \"_\" + factor] = talib.KAMA(data[factor], timeperiod=days)\n",
    "        return data\n",
    "    \n",
    "    def MAMA(self, data, factor):\n",
    "    \n",
    "        mama, fama = talib.MAMA(data[factor], fastlimit=0.8, slowlimit=0.2)\n",
    "        data[\"MAMA_\" + factor] = mama\n",
    "        data[\"FAMA_\" + factor] = fama\n",
    "        return data\n",
    "    \n",
    "    def TEMA(self, data, factor, days):\n",
    "    \n",
    "        data[\"TEMA_\"+ str(days) + \"_\" + factor] = talib.TEMA(data[factor], timeperiod=days)\n",
    "        return data\n",
    "    \n",
    "    def TRIMA(self, data, factor, days):\n",
    "    \n",
    "        data[\"TRIMA_\"+ str(days) + \"_\" + factor] = talib.TRIMA(data[factor], timeperiod=days)\n",
    "        return data\n",
    "    \n",
    "    def WMA(self, data, factor, days):\n",
    "    \n",
    "        data[\"WMA_\"+ str(days) + \"_\" + factor] = talib.WMA(data[factor], timeperiod=days)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndicatorsAndTransforms:\n",
    "    \n",
    "    def technicalIndicators(self, df):\n",
    "    \n",
    "        #Compute Daily Return\n",
    "        data = df.copy()\n",
    "        data['Daily_Return'] = (data['Close'] - data['Open'])/data['Open']\n",
    "\n",
    "        time_periods = [14, 26, 52, 128, 252]\n",
    "        factors = ['Close', 'Daily_Return', 'Volume']\n",
    "\n",
    "        #Compute various types of Time and factor varying Moving Averages\n",
    "        mv = MovingAverages()\n",
    "        \n",
    "        for days in time_periods:\n",
    "            for factor in factors: \n",
    "                data = mv.SMA(data, factor, days)\n",
    "                data = mv.EMA(data, factor, days)\n",
    "                data = mv.DEMA(data, factor, days)\n",
    "                data = mv.KAMA(data, factor, days)\n",
    "                data = mv.TEMA(data, factor, days)\n",
    "                data = mv.TRIMA(data, factor, days)\n",
    "                data = mv.WMA(data, factor, days)\n",
    "\n",
    "        #Compute the Hilbert Transform and Mesa Adaptive Moving Average\n",
    "        for factor in factors: \n",
    "            data = mv.HT(data, factor)\n",
    "            #data = MAMA(data, factor)\n",
    "\n",
    "        close, open_, high, low, volume = data['Close'], data['Open'], data['High'], data['Low'], data['Volume']\n",
    "\n",
    "        #Compute Parabolic SAR\n",
    "        data['SAR'] = talib.SAR(high, low, acceleration=0.7, maximum=0.2)\n",
    "\n",
    "        #Compute various Momentum based Indicators\n",
    "\n",
    "        data['ADX_14'] = talib.ADX(high, low, close, timeperiod= 14)\n",
    "        data['ADXR_14'] = talib.ADXR(high, low, close, timeperiod= 14)\n",
    "        data['APO'] = talib.APO(close, fastperiod=12, slowperiod=26, matype=0)\n",
    "        data['aroondown_14'], data['aroonup_14'] = talib.AROON(high, low, timeperiod=14)\n",
    "        data['AROONOSC_14'] = talib.AROONOSC(high, low, timeperiod=14)\n",
    "        data['BOP_14'] = talib.BOP(open_, high, low, close)\n",
    "        data['CCI_14'] = talib.CCI(high, low, close, timeperiod=14)\n",
    "        data['CMO_14'] = talib.CMO(close, timeperiod=14)\n",
    "        data['DX_14'] = talib.DX(high, low, close, timeperiod=14)\n",
    "        data['macd'], data['macdsignal'], data['macdhist'] = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "        data['MFI_14'] = talib.MFI(high, low, close, volume, timeperiod=14)    \n",
    "        data['MINUS_DM_14'] = talib.MINUS_DM(high, low, timeperiod=14)\n",
    "        data['MOM_10'] = talib.MOM(close, timeperiod=10)\n",
    "        data['PLUS_DI_14'] = talib.PLUS_DI(high, low, close, timeperiod=14)\n",
    "        data['PLUS_DM_14'] = talib.PLUS_DM(high, low, timeperiod=14)\n",
    "        data['PPO'] = talib.PPO(close, fastperiod=12, slowperiod=26, matype=0)\n",
    "        data['ROC_10'] = talib.ROC(close, timeperiod=10)\n",
    "        data['ROCP_10'] = talib.ROCP(close, timeperiod=10)\n",
    "        data['ROCR'] = talib.ROCR(close, timeperiod=10)\n",
    "        data['ROCR'] = talib.ROCR100(close, timeperiod=10)\n",
    "        data['RSI_14'] = talib.RSI(close, timeperiod=14)\n",
    "        data['RSI_26'] = talib.RSI(close, timeperiod=26)\n",
    "        data['STOCH_slowk'], data['STOCH_slowd'] = talib.STOCH(high, low, close, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "        data['STOCH_fastk'], data['STOCH_fastd'] = talib.STOCHF(high, low, close, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "        data['STOCHRSI_fastk'], data['STOCHRSI_fastd'] = talib.STOCHRSI(close, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "        data['TRIX_30'] = talib.TRIX(close, timeperiod=30)\n",
    "        data['ULTOSC'] = talib.ULTOSC(high, low, close, timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
    "        data['WILLR'] = talib.WILLR(high, low, close, timeperiod=14)\n",
    "\n",
    "\n",
    "        #Volality Indicator Functions\n",
    "        data['ATR_14'] = talib.ATR(high, low, close, timeperiod=14)\n",
    "        data['NATR_14'] = talib.NATR(high, low, close, timeperiod=14)\n",
    "        data['TRANGE'] = talib.TRANGE(high, low, close)\n",
    "\n",
    "        #Volume Indicator Functions\n",
    "        data['AD'] = talib.AD(high, low, close, volume)\n",
    "        data['ADOSC'] = talib.ADOSC(high, low, close, volume, fastperiod=3, slowperiod=10)\n",
    "        data['OBV'] = talib.OBV(close, volume)\n",
    "\n",
    "        #Moving Average Convergence Divergence\n",
    "        data['ema26_close'] = data['Close'].ewm(span = 26).mean()\n",
    "        data['ema12_close'] = data['Close'].ewm(span = 12).mean()\n",
    "        data['MACD'] = (data['ema12_close']-data['ema26_close'])\n",
    "\n",
    "        #Bollinger Bands\n",
    "        data['sd_Close_14'] = data['Close'].rolling(14).std()\n",
    "        data['upper_band_14'] = data['SMA_14_Close'] + (data['sd_Close_14']*2)\n",
    "        data['lower_band_14'] = data['SMA_14_Close'] - (data['sd_Close_14']*2)\n",
    "\n",
    "        #Exponential Moving Average\n",
    "        data['ema_close'] = data['Close'].ewm(com=0.4).mean()\n",
    "\n",
    "        # Create Momentum\n",
    "        data['momentum'] = data['Close']-1\n",
    "        #data['log_momentum'] = np.log(data['momentum'])\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessData:\n",
    "    def _init_(self):\n",
    "        pass\n",
    "    def technicalData(self, data):\n",
    "\n",
    "        df = data.copy()\n",
    "        df.columns = df.iloc[1]\n",
    "        df = df[3:]\n",
    "        df = df.set_index('Date')\n",
    "        df = df.rename(columns={\"Price\": \"Close\"})\n",
    "        df = df.rename(columns={\"CVol\": \"Volume\"})\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourrierTransform(df):\n",
    "    \n",
    "    data = df.copy()\n",
    "    data_FT = data[['Date', 'Close']]\n",
    "    close_fft = np.fft.fft(np.asarray(data_FT['Close'].tolist()))\n",
    "    fft_df = pd.DataFrame({'fft':close_fft})\n",
    "    fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
    "    fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))\n",
    "    plt.figure(figsize=(14, 7), dpi=100)\n",
    "    fft_list = np.asarray(fft_df['fft'].tolist())\n",
    "    for num_ in [7, 10, 14, 21, 50, 40, 100]:\n",
    "        fft_list_m10= np.copy(fft_list); fft_list_m10[num_:-num_]=0\n",
    "        #plt.plot(np.fft.ifft(fft_list_m10), label='Fourier transform with {} components'.format(num_))\n",
    "        data['Close_FFT_' + str(num_)] = abs(np.fft.ifft(fft_list_m10))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"WFC-US_Price.xlsx\")\n",
    "p = ProcessData()\n",
    "df = p.technicalData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = IndicatorsAndTransforms()\n",
    "df1 = df.copy()\n",
    "df1 = df1[::-1]\n",
    "df1 = t.technicalIndicators(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.fillna(method = 'bfill')\n",
    "df_tech = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Fundamental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time_parser(data):\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        str_ = data[i]\n",
    "        str_ = str_.strip()\n",
    "        str_ = str_.split('\\'')\n",
    "        #print (str_)\n",
    "        \n",
    "        \n",
    "        if (int(str_[1]) >= 70):\n",
    "            str_[1] = \"19\" + str_[1]\n",
    "        else:\n",
    "            str_[1] = \"20\" + str_[1]\n",
    "\n",
    "        str_[0] = str_[0].strip()\n",
    "\n",
    "        if (str_[0] == 'JAN'):\n",
    "            str_[0] = \"01\"\n",
    "        elif(str_[0] == 'FEB'):\n",
    "            str_[0] = \"02\"\n",
    "        elif(str_[0] == 'MAR'):\n",
    "            str_[0] = \"03\"\n",
    "        elif(str_[0] == 'APR'):\n",
    "            str_[0] = \"04\"\n",
    "        elif(str_[0] == 'MAY'):\n",
    "            str_[0] = \"05\"\n",
    "        elif(str_[0] == 'JUN'):\n",
    "            str_[0] = \"06\"\n",
    "        elif(str_[0] == 'JUL'):\n",
    "            str_[0] = \"07\"\n",
    "        elif(str_[0] == 'AUG'):\n",
    "            str_[0] = \"08\"\n",
    "        elif(str_[0] == 'SEP'):\n",
    "            str_[0] = \"09\"\n",
    "        elif(str_[0] == 'OCT'):\n",
    "            str_[0] = \"10\"\n",
    "        elif(str_[0] == 'NOV'):\n",
    "            str_[0] = \"11\"\n",
    "        elif(str_[0] == 'DEC'):\n",
    "            str_[0] = \"12\"\n",
    "\n",
    "        s = str_[1] + \"-\" + str_[0] + \"-10\"\n",
    "        data[i] = s\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    \n",
    "    #Convert datatypes from object/string to float and fill missing values with previous values\n",
    "    for col in data.columns:\n",
    "        #print (col)\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "        #data[col] = data[col].fillna(method = \"pad\")\n",
    "        data[col] = data[col].fillna(0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFundamentalData(data):\n",
    "    \n",
    "    df = data.copy()\n",
    "    df['Date'] = date_time_parser(df['Date'])\n",
    "    date_pd = df['Date']\n",
    "    df = df.set_index(['Date'])\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = data_cleaning(df)\n",
    "    df = df.resample(\"D\").asfreq().ffill()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FundamentalDataset:\n",
    "    def _init_(self):\n",
    "        pass\n",
    "    \n",
    "    def incomeStatement(self, data):\n",
    "        df_income = data.copy()\n",
    "        del df_income['EPS (recurring)']\n",
    "        del df_income['EPS (diluted)']\n",
    "        df_income = processFundamentalData(df_income)\n",
    "        \n",
    "        return df_income\n",
    "    \n",
    "    def otherData(self, data):\n",
    "        \n",
    "        df_other = data.copy()\n",
    "        df_other = processFundamentalData(df_other)\n",
    "        \n",
    "        return df_other\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund = FundamentalDataset()\n",
    "data_income = pd.read_excel(\"WFC-US_Income.xlsx\")\n",
    "data_bs = pd.read_excel(\"WFC-US_BalanceSheet_Change.xlsx\")\n",
    "data_cf = pd.read_excel(\"WFC-US_Cashflow.xlsx\")\n",
    "data_ratio1 = pd.read_excel(\"WFC-US_Ratio_Profitablity.xlsx\")\n",
    "data_ratio2 = pd.read_excel(\"WFC-US_Ratio_Valuation.xlsx\")\n",
    "data_ratio3 = pd.read_excel(\"WFC-US_Ratio_PerShare.xlsx\")\n",
    "data_ratio4 = pd.read_excel(\"WFC-US_Ratio_Liquidity.xlsx\")\n",
    "data_estimate = pd.read_excel(\"WFC-US_EPS_Estimates.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_income = fund.incomeStatement(data_income)\n",
    "df_bs = fund.otherData(data_bs)\n",
    "df_cf= fund.otherData(data_cf)\n",
    "df_r1 = fund.otherData(data_ratio1)\n",
    "df_r2 = fund.otherData(data_ratio2)\n",
    "df_r3 = fund.otherData(data_ratio3)\n",
    "df_r4 = fund.otherData(data_ratio4)\n",
    "df_estimate = fund.otherData(data_estimate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t1 = pd.merge(df_tech, df_income, how='inner', on='Date')\n",
    "df_t2 = pd.merge(df_t1, df_bs, how='inner', on='Date')\n",
    "df_t3 = pd.merge(df_t2, df_cf, how='inner', on='Date')\n",
    "df_t4 = pd.merge(df_t3, df_r1, how='inner', on='Date')\n",
    "df_t5 = pd.merge(df_t4, df_r2, how='inner', on='Date')\n",
    "df_t6 = pd.merge(df_t5, df_r3, how='inner', on='Date')\n",
    "df_t7 = pd.merge(df_t6, df_r4, how='inner', on='Date')\n",
    "df_t8 = pd.merge(df_t7, df_estimate, how='inner', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t8.to_excel(\"WFC-US_Final0.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(\"WFC-US_Final0.xlsx\")\n",
    "df = fourrierTransform(df)\n",
    "df.to_excel(\"WFC-US_Final0.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
